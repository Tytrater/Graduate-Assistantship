{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5497013f-5a08-45b2-a7f4-2cfcf6ded847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\SynologyDrive\\School\\School\\MSDataScience\\Teaching Assistant\\IS 471- Big Data Analytics\\Fall 2024\\Assignments\\Assignment 4- Functions\n",
      "['Assignment 4 Solution.ipynb', 'Assignment4.pdf', 'submissions.zip']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "from zipfile import ZipFile\n",
    "print(os.getcwd())\n",
    "print(os.listdir())\n",
    "path = 'Assignments'\n",
    "path+= input('assignment directory')                              \n",
    "os.chdir(path)\n",
    "if 'submissions.zip' in os.listdir():\n",
    "    with ZipFile('submissions.zip','r') as zip_file:\n",
    "        zip_file.extractall('submissions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07c2bc2a-fe15-4b1f-ad90-55c8b602e75f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'fsubmissions/{name_student}.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m         code\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m         comments \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfsubmissions/\u001b[39m\u001b[38;5;132;01m{name_student}\u001b[39;00m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 9\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(comments,mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m     10\u001b[0m             file\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     11\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m:name,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m'\u001b[39m:code})\n",
      "File \u001b[1;32m~\\Programs\\Anaconda\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    308\u001b[0m     )\n\u001b[1;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'fsubmissions/{name_student}.txt'"
     ]
    }
   ],
   "source": [
    "name = []\n",
    "code = []\n",
    "for file in os.listdir('submissions'):\n",
    "    if file.endswith('ipynb'):\n",
    "        name_student = file.split('_')[0]\n",
    "        name.append(name_student)\n",
    "        code.append('')\n",
    "        comments = 'fsubmissions/{name_student}.txt'\n",
    "        with open(comments,mode='w') as file:\n",
    "            file.write('')\n",
    "df = pd.DataFrame({'name':name,'code':code})\n",
    "df.to_csv('grades.csv')\n",
    "\n",
    "header = ['code','deduction','detail']\n",
    "code = [1]\n",
    "deduction = [0]\n",
    "detail = ['Full Credit']\n",
    "for i in range(2,11):\n",
    "    code.append(i)\n",
    "    deduction.append('')\n",
    "    detail.append('')\n",
    "data = {'code':code,'deduction':deduction,'detail':detail}\n",
    "df = pd.DataFrame(data,columns=header).set_index('code')\n",
    "df.to_csv('codes.csv')\n",
    "\n",
    "comments = '1'\n",
    "comments += '\\n'*1 \n",
    "comments += 'Good job  !' \n",
    "comments += '\\n'*2\n",
    "comments +='~'*110\n",
    "for i in range(2,11):\n",
    "    comments += i\n",
    "    comments += '\\n'*4\n",
    "    comments +='~'*110\n",
    "with open('comments.txt',mode='w') as file:\n",
    "    file.write(comments)\n",
    "\n",
    "def extract_markdown(file):\n",
    "    with open(file,'r') as file:\n",
    "        notebook = json.load(file)\n",
    "    \n",
    "    markdown_cells = [cell['source'] for cell in notebook['cells'] if cell['cell_type'] == 'markdown']\n",
    "\n",
    "    for i,cell in enumerate(markdown_cells):\n",
    "        print(''.join(cell))\n",
    "\n",
    "extract_markdown('Assignment 4 Solution.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0c8f4c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### MIS 776\n",
      "# Assignment 3 â€“ Clustering and Model Improvement\n",
      "### _Question 1_\n",
      "### _Question 2_\n",
      "### _Question 3_\n",
      "***\n",
      "#### R-squared = 0.7343\n",
      "#### Mean squared error = 22.430\n",
      "***\n",
      "### _Question 4_\n",
      "### _Question 5_\n",
      "***\n",
      "#### I might name the first cluster as \"employment hub\" for its high proportion of residential land zoned for large lots, closeness to five Boston employment centers, high proportion of non-retail businesses in the area; and I might name cluster 2 as \"city outskirts\" for its high distance from five Boston employment centers, high accessibility to radial highways, and high presence of lower-status population.\n",
      "***\n",
      "### _Question 6_\n",
      "***\n",
      "#### I might name The first cluster as \"old town\" for its high proportion of non-retail business acres, high pupil-teacher ratio (low likelihood of family units being present there), and high presence of homes built prior to 1940; the second cluster as \"rural\" for its extremely low crime rates  and moderate distance away from five Boston employment centers; and the thoird cluster as \"industrial\" for the percentage of non-business retail acres, high accessibility to radial highways (great for transporting large industrial goods), and high presence of lower-status population (presumably working class people in the industrial sectors).\n",
      "\n",
      "#### Adding the 3rd cluster does not help partition the data. By comparing the silhouette scores between a kmeans with 2 and 3 clusters, we can see that there is a score decrease. Also, looking at the count in each cluster, it appears that one of the clusters in the 2 node set was just split into two. So a lower score suggests a less efficient model with 2 verus three clusters.  However, if you are able to isolate a particular feature of interest within a specific cluster, it still might be useful regardless of the overall scores.\n",
      "***\n",
      "### _Question 7_\n",
      "### _Question 8_\n",
      "### _Question 9_\n",
      "### _Question 10_\n",
      "***\n",
      "#### R-squared = 0.861\n",
      "#### Mean squared error = 9.643\n",
      "#### Both the R-squared value and MSE are significantly higher than the baseline model.\n",
      "***\n",
      "### _Question 11_\n",
      "***\n",
      "#### R-squared = 0.683\n",
      "#### Mean squared error = 22.549\n",
      "#### The R-squared value is slightly lower than the baseline model, while MSE is slightly higher than the baseline model.\n",
      "***\n",
      "### _Question 12_\n",
      "### Clustering may improve the ability to predict the MEDV relative to a baseline model, but its dependent on their respective specific clusters. As we see from this example, one of the clusters improved but the other degraded. If one of the clusters is more interesting for some reason, and we can improve the performance for that cluster, then this would be a wiin.  Not all clusters may be improved, however, and an increase in one cluster may be offset by a decrease in another.  Therefore, the technique is useful but may be situational depending on the cluster(s) of interest for your analysis.\n"
     ]
    }
   ],
   "source": [
    "extract_markdown('Assignment 3 Solution.ipynb')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
